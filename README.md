ğŸ“Š Projeto Big Data â€” Scraping e DashboardEste repositÃ³rio contÃ©m um projeto de Big Data e Engenharia de Dados desenvolvido para fins acadÃªmicos. O objetivo Ã© criar um pipeline automatizado que realiza a extraÃ§Ã£o (scraping), transformaÃ§Ã£o (limpeza) e visualizaÃ§Ã£o de dados de livros.O sistema acessa o site Books to Scrape, coleta informaÃ§Ãµes dos primeiros livros listados e apresenta anÃ¡lises em um dashboard interativo.ğŸ› ï¸ Tech StackLinguagem: Python 3VisualizaÃ§Ã£o: StreamlitManipulaÃ§Ã£o de Dados: PandasWeb Scraping: Selenium + WebDriver Manager (Modo Headless)ğŸ“‚ Estrutura do Projetoprojeto_bigdata/
â”œâ”€ .venv/                 # Ambiente virtual (dependÃªncias instaladas)
â”œâ”€ app.py                 # AplicaÃ§Ã£o Principal: Coleta, Limpeza e Dashboard
â”œâ”€ scrape_test.py         # Script utilitÃ¡rio para testar o scraping isoladamente
â”œâ”€ requirements.txt       # Lista de dependÃªncias do projeto
â””â”€ README.md              # DocumentaÃ§Ã£o do projeto
DescriÃ§Ã£o dos Arquivosapp.py: O nÃºcleo do projeto. ContÃ©m a lÃ³gica do Streamlit e o botÃ£o "Iniciar Coleta". Ele gerencia o driver do Selenium, trata erros, limpa os dados (removendo sÃ­mbolos de moeda) e gera os grÃ¡ficos.scrape_test.py: Script auxiliar para validar a lÃ³gica de extraÃ§Ã£o via terminal, sem a necessidade de subir a interface grÃ¡fica.requirements.txt: Arquivo para reproduÃ§Ã£o do ambiente (versÃµes do Selenium, Pandas, etc.).ğŸš€ Como Executar (macOS/Linux)Siga os passos abaixo para rodar a aplicaÃ§Ã£o utilizando o terminal (zsh/bash).1. Ativar o Ambiente VirtualCertifique-se de estar na raiz do projeto ou ajuste o caminho conforme necessÃ¡rio.# Exemplo usando caminho absoluto (ajuste para o seu usuÃ¡rio se necessÃ¡rio)
source /Users/willianrodriguespiments/Desktop/projeto_bigdata/.venv/bin/activate

# OU, se estiver na pasta do projeto:
source .venv/bin/activate
2. Rodar o DashboardInicie o servidor do Streamlit:streamlit run app.py
O navegador abrirÃ¡ automaticamente em http://localhost:8501.3. Testes RÃ¡pidos (Opcional)Para verificar se as bibliotecas estÃ£o instaladas corretamente ou testar o scraping sem interface:# Teste de importaÃ§Ã£o
python -c "import streamlit, pandas, selenium, webdriver_manager; print('âœ… Imports OK')"

# Teste do script de scraping
python scrape_test.py
âš™ï¸ Funcionamento TÃ©cnicoInicializaÃ§Ã£o: O usuÃ¡rio clica em "Iniciar Coleta" no dashboard.ExtraÃ§Ã£o (Scraping): O webdriver_manager instala/atualiza o driver do Chrome. O Selenium abre o navegador em modo --headless (sem interface grÃ¡fica) e extrai o TÃ­tulo e PreÃ§o dos livros.TransformaÃ§Ã£o (ETL): O Pandas recebe os dados brutos. A coluna de preÃ§o Ã© limpa (remoÃ§Ã£o do sÃ­mbolo Â£) e convertida para numÃ©rico (float).VisualizaÃ§Ã£o: O Streamlit exibe:Tabela de dados (DataFrame).MÃ©trica de preÃ§o mÃ©dio.GrÃ¡fico de barras comparativo.ResiliÃªncia (Fallback): Se o Selenium falhar (por falta do Chrome ou incompatibilidade de driver), o sistema captura a exceÃ§Ã£o e utiliza um Mock Data (dados fictÃ­cios) para garantir que a apresentaÃ§Ã£o nÃ£o seja interrompida.âš ï¸ Troubleshooting (Problemas Comuns)Exec Format Error / Incompatibilidade de DriverSe ocorrer erro indicando incompatibilidade entre arquiteturas (ARM vs x86) ou versÃ£o do Chrome:SoluÃ§Ã£o AutomÃ¡tica (App): O app passarÃ¡ a usar dados de teste (mock) automaticamente.CorreÃ§Ã£o Manual: Limpe o cache do gerenciador de drivers para forÃ§ar o download da versÃ£o correta:rm -rf ~/.wdm
